# SDC
<!-- Intall first 
pip install xgboost scikit-learn pandas
Data 
Slingshot Seradata
SlingShot Aerospace 
 www.seradata.com -->

# ğŸš€ Conjunction Risk Prediction using Machine Learning
*A complete machineâ€‘learning pipeline for predicting highâ€‘risk satellite conjunctions using CDM data.*

---

## ğŸ“Œ Overview

This project builds an endâ€‘toâ€‘end system to identify **highâ€‘risk conjunction events** in Low Earth Orbit (LEO).  
As the number of satellites and debris increases, operators receive thousands of Conjunction Data Messages (CDMs), but only a small fraction represent real danger.  
This project aims to:

- Clean and standardize CDM data  
- Remove leakage features  
- Train multiple ML models  
- Compare their performance  
- Build a recallâ€‘focused ensemble for safer screening  

The final system helps operators **prioritize risky encounters** without replacing human judgment.

---

## ğŸ“‚ Project Structure
 


---

## ğŸ§¹ Data Processing

We combine **six CDM files** into a single dataset of **574,289 rows**.  
Key preprocessing steps include:

- Standardizing column names  
- Converting condition flags into boolean features  
- Labelâ€‘encoding categorical fields  
- Adding `hours_to_tca`  
- Removing leakage features for noâ€‘leak variants  
- Creating engineered features (distance ratios, uncertainty indicators, etc.)

The final featured dataset contains **33 columns**.

---

## ğŸ¤– Models Used

### **1. FTâ€‘Transformer**
- Works directly on tabular data  
- Uses embeddings + attention  
- Predicts both Pc and HighRisk probability  
- Very strong performance on original data  

### **2. XGBoost (4 variants)**
- Original  
- Featured  
- Noâ€‘Leak  
- Noâ€‘Leak + Featured  
- Hyperparameters tuned using Optuna  

### **3. LightGBM (4 variants)**
- Same four variants as XGBoost  
- Fast and efficient baseline  

### **4. Ensemble**
- Combines 4 XGBoost + 4 LightGBM models  
- Weighted using Optuna  
- Designed for **maximum recall** with acceptable precision  

---

## ğŸ“Š Evaluation

Each model is evaluated using:

- Recall  
- Precision  
- F1â€‘Score  
- Accuracy  
- AUCâ€‘ROC  
- AUCâ€‘PR  
- Confusion matrices  
- Threshold scanning (to maximize recall with precision â‰¥ 0.50)

All results are saved as JSON for reproducibility.

---

## ğŸ“ Key Findings

- Models **without leakage** struggle but still learn useful patterns.  
- Engineered features significantly improve performance.  
- Models **with leakage** perform almost perfectly because they see the fields used to define the label.  
- FTâ€‘Transformer is extremely strong on original data.  
- The ensemble achieves **100% recall**, making it suitable for safetyâ€‘critical screening.

---

## ğŸ› ï¸ How to Run

### 1. Install dependencies
```bash
pip install -r requirements.txt


python src/preprocessing.py